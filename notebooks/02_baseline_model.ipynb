{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704c1a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last executed: 2025-12-28 12:23:10\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print(\"Last executed: \" + now.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ecb19",
   "metadata": {},
   "outputs": [],
   "source": "# initial imports\nimport sys\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\n\n# Find project root and add to path\nPROJECT_ROOT = Path.cwd()\nwhile not (PROJECT_ROOT / \"src\").exists() and PROJECT_ROOT != PROJECT_ROOT.parent:\n    PROJECT_ROOT = PROJECT_ROOT.parent\n\nSRC_DIR = PROJECT_ROOT / \"src\"\nif str(SRC_DIR) not in sys.path:\n    sys.path.insert(0, str(SRC_DIR))\n\ntf.keras.utils.set_random_seed(639256)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff055ea7",
   "metadata": {},
   "outputs": [],
   "source": "# Import utilities (now that sys.path is set)\nfrom data.g2net import find_dataset_dir, load_labels, load_sample\nfrom models.base_model import LogRegBaseline, compute_features\n\nDATASET_DIR = find_dataset_dir()  # should resolve to D:\\Programming\\g2net-gravitational-wave-detection\nprint(\"DATASET_DIR:\", DATASET_DIR)\nFEAT_PATH = DATASET_DIR / \"features_logreg_full.npz\"\n\nDETECTORS = [\"Hanford (H1)\", \"Livingston (L1)\", \"Virgo (V1)\"]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c5e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all: (560000, 30) float32\n",
      "y_all: (560000,) int64\n",
      "Validation ROC-AUC: 0.5163768033194686\n"
     ]
    }
   ],
   "source": [
    "# Load labels\n",
    "df = load_labels(DATASET_DIR) # (id, target)\n",
    "y_df = df[\"target\"].astype(int).to_numpy()\n",
    "\n",
    "# Load precomputed features\n",
    "z = np.load(FEAT_PATH)\n",
    "X_all = z[\"X\"].astype(np.float32)\n",
    "y_all = z[\"y\"].astype(np.int64)\n",
    "\n",
    "print(\"X_all:\", X_all.shape, X_all.dtype)\n",
    "print(\"y_all:\", y_all.shape, y_all.dtype)\n",
    "\n",
    "# Sanity checks\n",
    "assert len(df) == X_all.shape[0] == y_all.shape[0], \"Mismatch between labels and feature rows\"\n",
    "assert np.array_equal(y_df, y_all), \"Label order mismatch: y from CSV != y saved in npz\"\n",
    "\n",
    "# Split into 80% train, 20% validation\n",
    "idx = np.arange(len(y_all))\n",
    "idx_tr, idx_va = train_test_split(\n",
    "    idx, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "X_tr, y_tr = X_all[idx_tr], y_all[idx_tr]\n",
    "X_va, y_va = X_all[idx_va], y_all[idx_va]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc5e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal baseline model: StandardScaler + LogisticRegression\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=2000, solver=\"lbfgs\")\n",
    ")\n",
    "\n",
    "pipe.fit(X_tr, y_tr)\n",
    "p_va = pipe.predict_proba(X_va)[:, 1]\n",
    "auc = roc_auc_score(y_va, p_va)\n",
    "print(\"Validation ROC-AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a8c346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num test samples: 226000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37525c1d6da467a977220b97d5bd300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: c:\\Users\\jose\\OneDrive\\Ambiente de Trabalho\\lisa_gravitational_wave_detector\\submission_logreg_baseline.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00005bced6</td>\n",
       "      <td>0.495248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000806717</td>\n",
       "      <td>0.481935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000ef4fe1</td>\n",
       "      <td>0.472083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00020de251</td>\n",
       "      <td>0.499208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00024887b5</td>\n",
       "      <td>0.515830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    target\n",
       "0  00005bced6  0.495248\n",
       "1  0000806717  0.481935\n",
       "2  0000ef4fe1  0.472083\n",
       "3  00020de251  0.499208\n",
       "4  00024887b5  0.515830"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on full training features\n",
    "pipe.fit(X_all, y_all)\n",
    "\n",
    "# Load sample submission to get test IDs\n",
    "sub = pd.read_csv(DATASET_DIR / \"sample_submission.csv\", dtype={\"id\": str})\n",
    "test_ids = sub[\"id\"].tolist()\n",
    "print(\"Num test samples:\", len(test_ids))\n",
    "\n",
    "# Compute features for test\n",
    "X_test = np.empty((len(test_ids), X_all.shape[1]), dtype=np.float32)\n",
    "\n",
    "for i, sample_id in enumerate(tqdm(test_ids)):\n",
    "    w = load_sample(sample_id, split=\"test\", dataset_dir=DATASET_DIR)\n",
    "    X_test[i] = compute_features(w)\n",
    "\n",
    "# Predict + write submission\n",
    "sub[\"target\"] = pipe.predict_proba(X_test)[:, 1]\n",
    "out_path = PROJECT_ROOT / \"submission_logreg_baseline.csv\"\n",
    "sub.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Wrote:\", out_path)\n",
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33c1459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 .npz files\n",
      "D:\\Programming\\g2net-gravitational-wave-detection\\features_logreg_full.npz 71680490\n"
     ]
    }
   ],
   "source": [
    "d = Path(find_dataset_dir())\n",
    "npzs = sorted(d.rglob(\"*.npz\"))\n",
    "print(\"Found\", len(npzs), \".npz files\")\n",
    "for p in npzs[:50]:\n",
    "    print(p, p.stat().st_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}